{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "# Memory leak with Matplotlib when in interactive mode and writing 1000+ plots\n",
    "matplotlib.use('agg')\n",
    "matplotlib.interactive(False)\n",
    "\n",
    "import obspy, os, glob\n",
    "\n",
    "CSV = 'Benz_catalog.csv' # 'OK_2014-2015-2016.csv' # \n",
    "FOLDER_NAME = 'modified_benz_without_08_2014'\n",
    "\n",
    "# In seconds\n",
    "DURATION = 20 \n",
    "\n",
    "# Seconds before event\n",
    "PRE_PADDING = 10\n",
    "\n",
    "# Seconds after event\n",
    "POST_PADDING = 10\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), 'data')\n",
    "SPECTROGRAM_PATH = os.path.join(os.getcwd(), f'spectrograms/{FOLDER_NAME}')\n",
    "\n",
    "stream_paths = glob.glob(os.path.join(DATA_PATH, 'train_mseed/*.mseed'))\n",
    "stream_paths += glob.glob(os.path.join(DATA_PATH, 'test_mseed/*.mseed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_paths = ['/data/notebooks/dataset_oklahoma/data/train_mseed/GSOK029_8-2014.mseed']\n",
    "\n",
    "for path in testing_paths:\n",
    "    stream_paths.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT SEISMIC TOOLBOX CODE\n",
    "import sys\n",
    "sys.path.insert(0, '/data/seismic_toolbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seismic_code.spectrograms as spectro\n",
    "import seismic_code.filter as filt\n",
    "from seismic_code import helpers\n",
    "from seismic_code.spectrograms import write_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date\n",
    "from collections import defaultdict\n",
    "from obspy import read\n",
    "\n",
    "class StreamPath:\n",
    "    def __init__(self, path):\n",
    "        self.raw_path = path\n",
    "        self.path = Path(path)\n",
    "        self.station = self.path.parts[-1].split('_')[0]\n",
    "        date_str = self.path.parts[-1].split('_')[1].replace('.mseed', \"\")\n",
    "        month, year = date_str.split('-')\n",
    "        self.date_start = date(int(year), int(month), day=1)\n",
    "        \n",
    "    def load(self):\n",
    "        \"\"\" Loads a stream from the path \"\"\"\n",
    "        return read(self.raw_path)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.raw_path\n",
    "    \n",
    "paths = list(map(StreamPath, stream_paths))\n",
    "#s1_date_paths = {stream.date_start: stream for stream in paths if stream.station == 'GSOK027'}\n",
    "s1_date_paths = {stream.date_start: stream for stream in paths if stream.station == 'GSOK029'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import Stream\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "from obspy import read\n",
    "\n",
    "# Combine all streams into one\n",
    "# stream = reduce(add, map(read, stream_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "quake_csv = pd.read_csv(os.path.join(DATA_PATH, CSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventNum</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Variance</th>\n",
       "      <th>origintime</th>\n",
       "      <th>utc_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>02/15/2014</td>\n",
       "      <td>00:02:41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2014-02-15T00:02:41.000000Z</td>\n",
       "      <td>1.392423e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02/15/2014</td>\n",
       "      <td>00:03:45</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2014-02-15T00:03:45.000000Z</td>\n",
       "      <td>1.392423e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>02/15/2014</td>\n",
       "      <td>00:08:07</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2014-02-15T00:08:07.000000Z</td>\n",
       "      <td>1.392423e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02/15/2014</td>\n",
       "      <td>00:12:52</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2014-02-15T00:12:52.000000Z</td>\n",
       "      <td>1.392423e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>02/15/2014</td>\n",
       "      <td>00:14:09</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2014-02-15T00:14:09.000000Z</td>\n",
       "      <td>1.392423e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventNum        Date      Time  Magnitude  Variance  \\\n",
       "0         0  02/15/2014  00:02:41       0.37      0.95   \n",
       "1         1  02/15/2014  00:03:45      -0.44      0.86   \n",
       "2         2  02/15/2014  00:08:07      -0.18      0.93   \n",
       "3         3  02/15/2014  00:12:52       0.10      0.93   \n",
       "4         4  02/15/2014  00:14:09      -0.47      0.89   \n",
       "\n",
       "                    origintime  utc_timestamp  \n",
       "0  2014-02-15T00:02:41.000000Z   1.392423e+09  \n",
       "1  2014-02-15T00:03:45.000000Z   1.392423e+09  \n",
       "2  2014-02-15T00:08:07.000000Z   1.392423e+09  \n",
       "3  2014-02-15T00:12:52.000000Z   1.392423e+09  \n",
       "4  2014-02-15T00:14:09.000000Z   1.392423e+09  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_column_name(df, column_index, new_name):\n",
    "    columns = df.columns.values\n",
    "    columns[column_index] = new_name\n",
    "    df.columns = columns\n",
    "    \n",
    "change_column_name(quake_csv, 0, 'EventNum')\n",
    "\n",
    "quake_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "def gen_row_date(df):\n",
    "    for index, row in df.iterrows():\n",
    "        year, month, day = row.origintime[:10].split('-')\n",
    "        yield date(int(year), int(month), day=1), row\n",
    "        \n",
    "        \n",
    "def gen_filter_waves(df, date_paths, pre_padding=PRE_PADDING, post_padding=POST_PADDING, shift_left=0, shift_right=0, offset=1):\n",
    "    \"\"\"\n",
    "    :shift_left: make copies of event by shifting seconds in the left direction\n",
    "    :shift_right: make copies of event by shifting seconds in the right direction\n",
    "    :offset: how much to move each shift by (determines how many copies will be make)\n",
    "    \"\"\"\n",
    "    curr_date = None\n",
    "    stream = None\n",
    "\n",
    "    for dat, row in gen_row_date(df):\n",
    "        if dat != curr_date:\n",
    "            try:\n",
    "                stream_path = date_paths[dat]\n",
    "            except KeyError:\n",
    "                print(f\"{dat} not in the stream_path\")\n",
    "                continue\n",
    "                \n",
    "            stream = stream_path.load()\n",
    "            curr_date = dat\n",
    "            \n",
    "            \n",
    "        # If shifting...\n",
    "        for i in range(-1 * shift_left, shift_right+1, offset):\n",
    "            yield filt.filter_waveform(stream, UTCDateTime(row.origintime) + i, pre_padding, post_padding)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            # Start PRE_PADDING before event_time, end POST_PADDING after event_time\n",
    "            yield filt.filter_waveform(stream, UTCDateTime(row.origintime), pre_padding, post_padding)\n",
    "        \n",
    "def gen_filter_waves_from_times(times, date_paths, pre_padding=PRE_PADDING, post_padding=POST_PADDING):\n",
    "    curr_date = None\n",
    "    stream = None\n",
    "    i = 0\n",
    "    for time in times:\n",
    "        dat = date(int(time.year), int(time.month), day=1)\n",
    "        if dat != curr_date:\n",
    "            try:\n",
    "                stream_path = date_paths[dat]\n",
    "            except KeyError:\n",
    "                print(f\"{dat} not in the stream_path ({i})\", end='\\r')\n",
    "                i += 1\n",
    "                continue\n",
    "                \n",
    "            stream = stream_path.load()\n",
    "            curr_date = dat\n",
    "            \n",
    "        # Start PRE_PADDING before event_time, end POST_PADDING after event_time\n",
    "        yield filt.filter_waveform(stream, time, pre_padding, post_padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_paths = s1_date_paths\n",
    "amount_quakes_ = None   # Write all events if None\n",
    "amount_noise = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "quake_path = os.path.join(SPECTROGRAM_PATH, 'local')\n",
    "noise_path = os.path.join(SPECTROGRAM_PATH, 'noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Quakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 additional copies will be made\n",
    "shift_left = 5\n",
    "shift_right = 4\n",
    "total_shift = 9\n",
    "assert shift_left + shift_right == total_shift\n",
    "\n",
    "# To correct for the duplicate quakes\n",
    "if amount_quakes_ is None:\n",
    "    amount_quakes = None\n",
    "else:\n",
    "    amount_quakes = amount_quakes_ * (total_shift + 1) \n",
    "    \n",
    "# Create Quakes\n",
    "quake_waves = gen_filter_waves(quake_csv, date_paths, shift_left=shift_left, shift_right=shift_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Files...\n"
     ]
    }
   ],
   "source": [
    "# Write Quakes\n",
    "with warnings.catch_warnings():   \n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    spectro.async_write_spectrograms(islice(quake_waves, amount_quakes), \n",
    "                                     quake_path, ignoreexceptions=True, \n",
    "                                     write_streams=True,\n",
    "                                     continue_from_previous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_times(df):\n",
    "    times = df[['origintime']]\n",
    "    for row in times.iterrows():\n",
    "        time = row[1].origintime\n",
    "        yield UTCDateTime(time)\n",
    "\n",
    "times = sorted(get_csv_times(quake_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_times = helpers.get_noise_times(times_to_exclude=times, \n",
    "                                      startafter=times[0], \n",
    "                                      endbefore=times[-1],\n",
    "                                      amount=amount_noise, \n",
    "                                      duration=DURATION,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_times = sorted(noise_times)  # important, to make lazy_loading the streams better for the next function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise times centers around the given time by default... so pad X seconds in each direction\n",
    "noise_pad = DURATION / 2\n",
    "noise_waves = gen_filter_waves_from_times(noise_times, date_paths, noise_pad, noise_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Files...\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():   \n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    spectro.async_write_spectrograms(noise_waves, noise_path, ignoreexceptions=False, \n",
    "                                     write_streams=True,\n",
    "                                     continue_from_previous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(path):\n",
    "    \"\"\" Removes empty dirs \"\"\"\n",
    "    folders = glob.glob(os.path.join(path, '*/'))\n",
    "    for folder in folders:\n",
    "        if not os.listdir(folder):\n",
    "             os.rmdir(folder)\n",
    "\n",
    "clean_up(quake_path)\n",
    "clean_up(noise_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
